{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Prompts\n",
    "\n",
    "The base unit is a `Message(role, context)`, which has generally been accepted by all LLM chat APIs.\n",
    "\n",
    "A list of Messages is a `Conversation`, which provides easy conversion to a messages array for API calls.\n",
    "\n",
    "> _Hint: `yaaal` provides a `format_json()` function that pretty prints json for logging and debugging_\n",
    "\n",
    "Sometimes we may want to predefine the messages in the conversation via MessageTemplates.\n",
    "A `MessageTemplate` defines the role, the template, and the rendering method to generate a Message.\n",
    "It may also add variable validation with Pydantic through the `template_vars_model` attribute.\n",
    "\n",
    "- `StaticMessageTemplate` provides a prompt template that is not templated, that is, there are no template variables and it renders exactly the same string every time.\n",
    "- `StringMessageTemplate` uses string templates (_`$varname`, not `{varname}`!_) to render a templated string based on a dict provided at render-time.\n",
    "- `JinjaMessageTemplate` uses a jinja2 Template to render a templated string based on a dict provided at render-time.\n",
    "\n",
    "A `Prompt` is a way to use various MessageTemplates to render a `Conversation`.\n",
    "We may want to treat Prompts as Functions or Tools for the tool-calling API;\n",
    "Prompts provide a `signature` method to mock a function signature that details all of the template variables necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from pydantic import BaseModel, Field, create_model\n",
    "\n",
    "from yaaal.core.prompt import JinjaMessageTemplate, Prompt, StaticMessageTemplate, StringMessageTemplate\n",
    "from yaaal.types.base import JSON\n",
    "from yaaal.types.core import Conversation, Message\n",
    "from yaaal.utilities import basic_log_config, format_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_log_config()\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A `StaticMessageTemplate` provides a prompt template that is not templated, that is, there are no template variables and it renders exactly the same string every time.\n",
    "\n",
    "template = StaticMessageTemplate(role=\"system\", template=\"You are a helpful assistant.\")\n",
    "template.render_message()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A `StringMessageTemplate` uses string templates (_`$varname`, not `{varname}`!_) to render a templated string based on a dict provided at render-time.\n",
    "\n",
    "template = StringMessageTemplate(role=\"system\", template=\"You are a helpful assistant who specializes in $expertise.\")\n",
    "template.render_message(template_vars={\"expertise\": \"Star Wars trivia\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A `JinjaMessageTemplate` uses a jinja2 Template to render a templated string based on a dict provided at render-time.\n",
    "\n",
    "template = JinjaMessageTemplate(\n",
    "    role=\"system\", template=\"You are a helpful assistant who specializes in {{expertise}}.\"\n",
    ")\n",
    "template.render_message(template_vars={\"expertise\": \"Star Wars trivia\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `yaaal` has logged a warning message when we rendered our `StringMessageTemplate` and `JinjaMessageTemplate` messages.\n",
    "This is because we did not provide a `template_vars_model` - a Pydantic model that defines the expectations for template variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the Pydantic model that defines what we expect to accept as input\n",
    "\n",
    "\n",
    "class Expertise(BaseModel):\n",
    "    expertise: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use our model to validate the input\n",
    "\n",
    "template = JinjaMessageTemplate(\n",
    "    role=\"system\",\n",
    "    template=\"You are a helpful assistant who specializes in {{expertise}}.\",\n",
    "    template_vars_model=Expertise,\n",
    ")\n",
    "template.render_message(template_vars={\"expertise\": \"Star Wars trivia\"})\n",
    "\n",
    "# No warning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An invalid input will raise a ValidationError\n",
    "\n",
    "template = JinjaMessageTemplate(\n",
    "    role=\"system\",\n",
    "    template=\"You are a helpful assistant who specializes in {{expertise}}.\",\n",
    "    template_vars_model=Expertise,\n",
    ")\n",
    "template.render_message(template_vars={\"expertise\": 8675309})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Objective: Define a `Prompt` that provides a summarizes web content, with validation (this is a replica of the Summarizer Prompt provided as one of `yaaal`'s default Prompts)\n",
    "\n",
    "- Define system prompt template\n",
    "- Define user prompt template\n",
    "- Define output format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Templates\n",
    "\n",
    "It is often easiest to start by drafting the instructions / system template before defining input/output validators.\n",
    "Ultimately, the order doesn't particularly matter, except that all of the moving pieces must be defined before we use them to create the `Prompt`.\n",
    "\n",
    "> _Hint:_ [OpenAI](https://platform.openai.com/docs/guides/prompt-generation) and [Anthropic](https://www.anthropic.com/news/prompt-improver) provide meta-prompts that can help generate a well-defined set of instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a jinja string.\n",
    "# Jinja is a powerful templating language that lets us do things like loop over variables (see 'for source in sources' at end)\n",
    "summarizer_system_template_str = \"\"\"\n",
    "You are an AI research assistant. Your task is to summarize a piece of content and synthesize key takeaways. The user may provide additional guidance for topics of interest or directions for investigation.\n",
    "\n",
    "Please follow these steps to complete your task:\n",
    "\n",
    "1. Carefully read and analyze the provided content.\n",
    "2. Summarize the main points of the content. Your summary should be detailed and comprehensive, capturing the essence of the content and the source's relevance with respect to the user's guidance.\n",
    "3. If it exists, consider the user-provided guidance and ensure that your summary and analysis address the specified topics of interest or directions for investigation.\n",
    "4. The summary may use up to three paragraphs to highlight the main idea, argument or goal, clarify critical information, and identify actionable insights or key takeaways.\n",
    "5. Present your analysis adhering to the following json schema:\n",
    "\n",
    "<schema>\n",
    "{{summary_schema}}\n",
    "</schema>\n",
    "\n",
    "Here is the source you need to analyze:\n",
    "\n",
    "<sources>\n",
    "{% for source in sources %}\n",
    "    <source>\n",
    "    {{source}}\n",
    "    </source>\n",
    "{% endfor %}\n",
    "</sources>\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create Pydantic BaseModels to define our expectations around the source (`URLContent`, input) and response (`Summary`, output) schemas.  Note that the Summary schema used to validate the model response is also used to tell the model how to response in the system template!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume our \"sources\" come as URLContent objects\n",
    "class URLContent(BaseModel, extra=\"ignore\"):\n",
    "    \"\"\"Text content from a webpage.\"\"\"\n",
    "\n",
    "    url: str = Field(description=\"The webpage url\")\n",
    "    title: str = Field(description=\"The page title\")\n",
    "    content: str = Field(description=\"The webpage's text content\")\n",
    "\n",
    "\n",
    "# We want our output to have the Summary structure\n",
    "class Summary(BaseModel, extra=\"ignore\"):\n",
    "    url: str  # Annotated[str, AnyHttpUrl]\n",
    "    title: str\n",
    "    summary: str = Field(\n",
    "        description=\"A comprehensive but concise summary of the source content that captures the essence of the original information.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# This will ensure all inputs into the system template are valid\n",
    "class SummarizerSystemVarsValidator(BaseModel):\n",
    "    sources: list[URLContent] = Field(description=\"The text to be analyzed\", min_length=1)\n",
    "    summary_schema: dict[str, JSON] = Summary.model_json_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can construct and test the system prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer_system_template = JinjaMessageTemplate(\n",
    "    role=\"system\",\n",
    "    template=summarizer_system_template_str,\n",
    "    template_vars_model=SummarizerSystemVarsValidator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per our SummarizerSystemVarsValidator, our system template expects:\n",
    "# - sources, list of URLContent objects\n",
    "# - summary_schema, the json schema for the output (which is provided by default)\n",
    "summarizer_system_template.render_message(\n",
    "    template_vars={\n",
    "        \"sources\": [\n",
    "            URLContent(\n",
    "                url=\"http://this.is/an/example\",\n",
    "                title=\"example\",\n",
    "                content=\"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua\",\n",
    "            )\n",
    "        ],\n",
    "        # \"summary_schema\": Summary.model_json_schema(), # this has a default value in SummarizerSystemVarsValidator\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use a passthrough prompt to allow the user to provide their input using string templates\n",
    "# a `PassthroughMessageTemplate` exists specifically for this reason;\n",
    "# This example just recreates it.\n",
    "summarizer_user_template_str = \"$content\"\n",
    "\n",
    "\n",
    "# This will ensure all inputs into the user template are valid\n",
    "class SummarizerUserVarsValidator(BaseModel):\n",
    "    content: str\n",
    "\n",
    "\n",
    "summarizer_user_template = StringMessageTemplate(\n",
    "    role=\"user\",\n",
    "    template=summarizer_user_template_str,\n",
    "    template_vars_model=SummarizerUserVarsValidator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer_user_template.render_message({\"content\": \"Tell me about quantum entanglement.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We can use templates to render messages that change based on the variables we've configured, and we have validators that check to make sure the inputs are what we expect.\n",
    "\n",
    "Now, we want to combine the message templates into a conversation so we can send the whole thing to an LLM to receive a response.\n",
    "\n",
    "A `Prompt` is a way to use various MessageTemplates to render a `Conversation`.\n",
    "Prompts always require a system template (even if it's a static template), while user templates are optional.  This is because we may want the model to do something (e.g., extract text from a document into a structure format) that needs a system instruction for what to do, but has no further user input.\n",
    "\n",
    "Conveniently, our Prompt uses the templates we just defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer_prompt = Prompt(\n",
    "    name=\"Summarizer\",\n",
    "    description=\"Summarizes the content of web page(s)\",\n",
    "    system_template=summarizer_system_template,\n",
    "    user_template=summarizer_user_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of the template's `template_vars` parameter, now we make a distinction between `system_vars` and `user_vars` to properly associate the inputs with the template\n",
    "summarizer_prompt.render(\n",
    "    system_vars={\n",
    "        \"sources\": [\n",
    "            URLContent(\n",
    "                url=\"http://this.is/an/example\",\n",
    "                title=\"example\",\n",
    "                content=\"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua\",\n",
    "            )\n",
    "        ],\n",
    "        # \"summary_schema\": Summary.model_json_schema(), # this has a default value in SummarizerSystemVarsValidator\n",
    "    },\n",
    "    user_vars={\"content\": \"Tell me about quantum entanglement.\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that we had to provide `name` and `description` arguments to our Prompt.\n",
    "\n",
    "This is because we may want to treat the Prompt as a tool for function-calling.  Tool use works best when the tools have a descriptive name and detailed description about their function so the LLM can determine when they are appropriate to use.\n",
    "\n",
    "Concretely, `Prompt.signature()` returns a Pydantic model that defines the function signature of `Prompt.render()` for this use case.\n",
    "We can convert the signature to a json schema with `model_json_schema()`, or use something like openai's pydantic integration with `openai.pydantic_function_tool(summarizer_prompt.signature())`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the BaseModel\n",
    "display(summarizer_prompt.signature())\n",
    "display(type(summarizer_prompt.signature()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the json schema\n",
    "print(format_json(summarizer_prompt.signature().model_json_schema()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
