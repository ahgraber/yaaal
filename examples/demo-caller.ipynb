{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Caller` is the basic structure that wraps all logic required for LLM call-and-response.\n",
    "\n",
    "A `Caller` renders a conversation with a specific LLM client and call parameters (assumes OpenAI-compatibility through a framework like `aisuite`).\n",
    "This allows every Caller instance to use a different model and/or parameters, and sets expectations for the Caller instance.\n",
    "\n",
    "Additionally, `Callers` can be used as functions/tools in tool-calling workflows by leveraging `Caller.function_schema` which defines the inputs the Caller expects as a JSON schema.\n",
    "\n",
    "Since a `Caller` has a specific client and model assigned, this effectively allows us to use Callers to route to specific models for specific use cases.\n",
    "Since Callers can behave as functions themselves, we enable complex workflows where Callers can call Callers (ad infinitum ad nauseum)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "from string import Template as StringTemplate\n",
    "import textwrap\n",
    "from typing import cast\n",
    "\n",
    "from jinja2 import Template as JinjaTemplate\n",
    "import json_repair\n",
    "from pydantic import BaseModel, Field, ValidationError as PydanticValidationError, create_model\n",
    "\n",
    "import aisuite\n",
    "import openai\n",
    "\n",
    "from yaaal.core.caller import Caller\n",
    "from yaaal.core.handler import ResponseHandler, ToolHandler\n",
    "from yaaal.core.validator import PassthroughValidator, PydanticValidator, RegexValidator, ToolValidator\n",
    "from yaaal.types_.base import JSON\n",
    "from yaaal.types_.core import Conversation, Message\n",
    "from yaaal.utilities import basic_log_config, format_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_log_config()\n",
    "logging.getLogger(\"yaaal\").setLevel(logging.DEBUG)\n",
    "logger = logging.getLogger(__name__).setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all Callers require a client and a model to call.\n",
    "# `yaaal` is built around OpenAI-compatible APIs primarily provided by `aisuite`\n",
    "client = aisuite.Client(\n",
    "    provider_configs={\n",
    "        \"openai\": {\"api_key\": os.environ[\"YAAAL_OPENAI_API_KEY\"]},\n",
    "        \"anthropic\": {\"api_key\": os.environ[\"YAAAL_ANTHROPIC_API_KEY\"]},\n",
    "        # ...\n",
    "    }\n",
    ")\n",
    "# `aisuite` specifies models in \"provider:model\" format\n",
    "# model = \"openai:gpt-4o-mini\"\n",
    "model = \"anthropic:claude-3-5-haiku-latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 20:17:10,892 - DEBUG    - yaaal.core.caller - request_params:215 - All API requests for Caller will use params : {'temperature': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# A `ChatCaller`\n",
    "chat_caller = Caller(\n",
    "    client=client,\n",
    "    model=model,\n",
    "    request_params={\"temperature\": 0.7},\n",
    "    description=\"chat\",\n",
    "    instruction=\"You are a helpful assistant\",\n",
    "    # input_template=StringTemplate(\"$input\"),\n",
    "    # input_params=create_model(\n",
    "    #     \"Chat\",\n",
    "    #     __doc__=\"a chatbot\",\n",
    "    #     input=(str, ...),\n",
    "    # ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Caller's renders messages based on the instruction (used to create the System message), and the input_template (used to render the User message).\n",
    "\n",
    "An instruction may be string, StringTemplate, or JinjaTemplate.\n",
    "By default, the input_template is `None`, which corresponds to simply expecting `input` and passing it as a User message.\n",
    "\n",
    "If a template is provided for instructions or input_template, input_params must be specified so that the Caller understands what the expected kwargs are.\n",
    "\n",
    "Kwargs that are not `input` must be passed in the `state` dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"description\": \"chat\",\n",
      "  \"properties\": {\n",
      "    \"input\": {\n",
      "      \"title\": \"Input\",\n",
      "      \"type\": \"string\",\n",
      "    },\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"input\",\n",
      "  ],\n",
      "  \"title\": \"caller\",\n",
      "  \"type\": \"object\",\n",
      "  \"additionalProperties\": false,\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Caller `function_schema` attribute is based on its Prompt signature\n",
    "print(format_json(str(chat_caller.function_schema)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[{\n",
      "  \"role\": \"system\",\n",
      "  \"content\": \"You are a helpful assistant\",\n",
      "}, {\n",
      "  \"role\": \"user\",\n",
      "  \"content\": \"Who is Harry Potter?\",\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "# Render conversation using the new render method\n",
    "print(chat_caller.render(input=\"Who is Harry Potter?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter is a fictional character created by British author J.K.\n",
      "Rowling. He is the protagonist of the widely popular Harry Potter book\n",
      "series, which consists of seven novels published between 1997 and\n",
      "2007. In the story, Harry is a young wizard who discovers on his 11th\n",
      "birthday that he is famous in the magical world for surviving an\n",
      "attack by the evil dark wizard Lord Voldemort when he was an infant.\n",
      "Key details about Harry Potter include:\n",
      "\n",
      "1. Orphaned as a baby when\n",
      "Voldemort killed his parents, Lily and James Potter\n",
      "2. Raised by his\n",
      "non-magical (Muggle) aunt and uncle, the Dursleys\n",
      "3. Attends Hogwarts\n",
      "School of Witchcraft and Wizardry\n",
      "4. Belongs to Gryffindor House\n",
      "5.\n",
      "Known for his distinctive lightning bolt-shaped scar\n",
      "6. Becomes a\n",
      "central figure in the fight against Lord Voldemort\n",
      "7. Best friends\n",
      "with Ron Weasley and Hermione Granger\n",
      "\n",
      "The book series follows Harry's\n",
      "adventures from ages 11 to 17, chronicling his growth, magical\n",
      "education, and ultimate confrontation with Voldemort. The books were\n",
      "adapted into a highly successful film series starring Daniel Radcliffe\n",
      "as Harry Potter.\n"
     ]
    }
   ],
   "source": [
    "# Callers are callable; treat them like functions\n",
    "response = chat_caller(input=\"Who is Harry Potter?\")\n",
    "\n",
    "print(textwrap.fill(response, replace_whitespace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 20:22:04,777 - DEBUG    - yaaal.core.caller - request_params:215 - All API requests for Caller will use params : {'temperature': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# A `RegexCaller` validates the response with a regex pattern\n",
    "pattern = re.compile(r\"\\b[A-E]\\b(?!.*\\b[A-E]\\b)\")\n",
    "\n",
    "system_instructions = \"\"\"\n",
    "The following are multiple choice questions (with answers) about Star Wars.\n",
    "\n",
    "What is the model designation of an X-Wing?\n",
    "A. T-65B\n",
    "B. BTL-A4\n",
    "C. RZ-1\n",
    "D. A/SF-01\n",
    "Answer: A\n",
    "\"\"\"\n",
    "\n",
    "user_template = \"\"\"\n",
    "{{input}}\n",
    "Answer:\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "class MCQAQuestion(BaseModel):\n",
    "    \"\"\"Multiple choice question.\"\"\"\n",
    "\n",
    "    input: str = Field(..., description=\"The multiple choice question\")\n",
    "\n",
    "\n",
    "regex_caller = Caller(\n",
    "    client=client,\n",
    "    model=model,\n",
    "    request_params={\"temperature\": 0.7},\n",
    "    description=\"Multiple-choice question answering\",\n",
    "    instruction=system_instructions,\n",
    "    input_template=JinjaTemplate(user_template),\n",
    "    input_params=MCQAQuestion,\n",
    "    output_validator=pattern,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"description\": \"Multiple choice question.\",\n",
      "  \"properties\": {\n",
      "    \"input\": {\n",
      "      \"description\": \"The multiple choice question\",\n",
      "      \"title\": \"Input\",\n",
      "      \"type\": \"string\",\n",
      "    },\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"input\",\n",
      "  ],\n",
      "  \"title\": \"MCQAQuestion\",\n",
      "  \"type\": \"object\",\n",
      "  \"additionalProperties\": false,\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(format_json(str(regex_caller.function_schema)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[{\n",
      "  \"role\": \"system\",\n",
      "  \"content\": \"The following are multiple choice questions (with answers) about Star \n",
      "              Wars.             \n",
      "             \n",
      "             What is the model designation of an X-Wing?             \n",
      "             A. T-65B             \n",
      "             B. BTL-A4             \n",
      "             C. RZ-1             \n",
      "             D. A/SF-01             \n",
      "             Answer: A\",\n",
      "}, {\n",
      "  \"role\": \"user\",\n",
      "  \"content\": \"Han Solo is:             \n",
      "             A. A scoundrel             \n",
      "             B. A scruffy nerfherder             \n",
      "             C. A smuggler             \n",
      "             D. The owner of the Millennium Falcon             \n",
      "             E. All of the above             \n",
      "             Answer:\",\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "Han Solo is:\n",
    "A. A scoundrel\n",
    "B. A scruffy nerfherder\n",
    "C. A smuggler\n",
    "D. The owner of the Millennium Falcon\n",
    "E. All of the above\n",
    "\"\"\".strip()\n",
    "\n",
    "# Render conversation using the new render method\n",
    "print(regex_caller.render(input=question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E\n",
      "Success! ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "response = regex_caller(input=question)\n",
    "print(response)\n",
    "\n",
    "if response == \"E\":\n",
    "    print(\"Success! ðŸŽ‰\")\n",
    "# print(textwrap.fill(response, replace_whitespace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 20:17:25,786 - DEBUG    - yaaal.core.caller - request_params:215 - All API requests for Caller will use params : {'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'Person', 'strict': True, 'parameters': {'description': \"A Person's characteristics.\", 'properties': {'name': {'title': 'Name', 'type': 'string'}, 'age': {'title': 'Age', 'type': 'integer'}, 'favorite_color': {'title': 'Favorite Color', 'type': 'string'}}, 'required': ['name', 'age', 'favorite_color'], 'title': 'Person', 'type': 'object', 'additionalProperties': False}, 'description': \"A Person's characteristics.\"}}], 'tool_choice': {'type': 'tool', 'name': 'Person'}}\n"
     ]
    }
   ],
   "source": [
    "# A `StructuredCaller` validates the response with a Pydantic model, and is good for structure data extraction\n",
    "class Person(BaseModel, extra=\"ignore\"):\n",
    "    \"\"\"A Person's characteristics.\"\"\"\n",
    "\n",
    "    name: str\n",
    "    age: int\n",
    "    favorite_color: str\n",
    "\n",
    "\n",
    "# Notes on fstrings with jinja templates --\n",
    "# The fstring allows us to substitute in variables before\n",
    "# dynamically rendering the template in the Prompt.\n",
    "# Because we're using fstrings, we have to double the `{}`\n",
    "# so python understands they do not indicate an fstring substitution.\n",
    "system_instructions = f\"\"\"\n",
    "Identify facts about a person as they introduce themselves.\n",
    "\n",
    "Respond in a format that matches the following json schema:\n",
    "\n",
    "<schema>\n",
    "{Person.model_json_schema()}\n",
    "</schema>\n",
    "\"\"\".strip()\n",
    "\n",
    "structured_caller = Caller(\n",
    "    client=client,\n",
    "    model=model,\n",
    "    request_params={\"temperature\": 0.7},\n",
    "    description=\"person details\",\n",
    "    instruction=system_instructions,\n",
    "    # input_template=JinjaTemplate(\"{{input}}\"),\n",
    "    # input_params=create_model(\n",
    "    #     \"structured_caller\",\n",
    "    #     __doc__=\"person details\",\n",
    "    #     input=(str, ...),\n",
    "    # ),\n",
    "    output_validator=Person,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"description\": \"person details\",\n",
      "  \"properties\": {\n",
      "    \"input\": {\n",
      "      \"title\": \"Input\",\n",
      "      \"type\": \"string\",\n",
      "    },\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"input\",\n",
      "  ],\n",
      "  \"title\": \"caller\",\n",
      "  \"type\": \"object\",\n",
      "  \"additionalProperties\": false,\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(format_json(str(structured_caller.function_schema)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[{\n",
      "  \"role\": \"system\",\n",
      "  \"content\": \"Identify facts about a person as they introduce themselves.             \n",
      "             \n",
      "             Respond in a format that matches the following json schema:             \n",
      "             \n",
      "             <schema>             \n",
      "             {'description': \"A Person's characteristics.\", 'properties': {'name': \n",
      "              {'title': 'Name', 'type': 'string'}, 'age': {'title': 'Age', 'type': \n",
      "              'integer'}, 'favorite_color': {'title': 'Favorite Color', 'type': \n",
      "              'string'}}, 'required': ['name', 'age', 'favorite_color'], 'title': \n",
      "              'Person', 'type': 'object'}             \n",
      "             </schema>\",\n",
      "}, {\n",
      "  \"role\": \"user\",\n",
      "  \"content\": \"Hi, my name is Bob and I'm 42.  I work in a button factory, and my \n",
      "              favorite color is blue.\",\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "introduction = \"\"\"\n",
    "Hi, my name is Bob and I'm 42.  I work in a button factory, and my favorite color is blue.\n",
    "\"\"\".strip()\n",
    "\n",
    "print(structured_caller.render(input=introduction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Person'>\n",
      "{\n",
      "  \"name\": \"Bob\",\n",
      "  \"age\": 42,\n",
      "  \"favorite_color\": \"blue\",\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = structured_caller(input=introduction)\n",
    "\n",
    "print(type(response))\n",
    "print(format_json(response.model_dump()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callers using Pydantic Handlers still return an AssistantMessage; it was validated internally before returning to the user.\n",
    "\n",
    "This means we still have to re-validate if we want the response as a Pydantic model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 20:24:47,768 - DEBUG    - yaaal.core.caller - request_params:215 - All API requests for Caller will use params : {'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'MCQAQuestion', 'strict': True, 'parameters': {'description': 'Multiple choice question.', 'properties': {'input': {'description': 'The multiple choice question', 'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'MCQAQuestion', 'type': 'object', 'additionalProperties': False}, 'description': 'Multiple choice question.'}}, {'type': 'function', 'function': {'name': 'caller', 'strict': True, 'parameters': {'description': 'person details', 'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'caller', 'type': 'object', 'additionalProperties': False}, 'description': 'person details'}}], 'tool_choice': {'type': 'auto'}}\n"
     ]
    }
   ],
   "source": [
    "# A `ToolCaller` can choose to call tools or respond like a normal LLM.\n",
    "tool_caller = Caller(\n",
    "    client=client,\n",
    "    model=model,\n",
    "    request_params={\"temperature\": 0.7},\n",
    "    description=\"tool use\",\n",
    "    instruction=\"Use the best tool for the task.\",\n",
    "    # input_template=\"{{input}}\",\n",
    "    # input_params=create_model(\"ToolInput\", input=(str, ...)),\n",
    "    tools=[regex_caller, structured_caller],\n",
    "    auto_invoke=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"description\": \"tool use\",\n",
      "  \"properties\": {\n",
      "    \"input\": {\n",
      "      \"title\": \"Input\",\n",
      "      \"type\": \"string\",\n",
      "    },\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"input\",\n",
      "  ],\n",
      "  \"title\": \"caller\",\n",
      "  \"type\": \"object\",\n",
      "  \"additionalProperties\": false,\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(format_json(str(tool_caller.function_schema)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"temperature\": 0.7,\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"MCQAQuestion\",\n",
      "        \"strict\": true,\n",
      "        \"parameters\": {\n",
      "          \"description\": \"Multiple choice question.\",\n",
      "          \"properties\": {\n",
      "            \"input\": {\n",
      "              \"description\": \"The multiple choice question\",\n",
      "              \"title\": \"Input\",\n",
      "              \"type\": \"string\",\n",
      "            },\n",
      "          },\n",
      "          \"required\": [\n",
      "            \"input\",\n",
      "          ],\n",
      "          \"title\": \"MCQAQuestion\",\n",
      "          \"type\": \"object\",\n",
      "          \"additionalProperties\": false,\n",
      "        },\n",
      "        \"description\": \"Multiple choice question.\",\n",
      "      },\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"caller\",\n",
      "        \"strict\": true,\n",
      "        \"parameters\": {\n",
      "          \"description\": \"person details\",\n",
      "          \"properties\": {\n",
      "            \"input\": {\n",
      "              \"title\": \"Input\",\n",
      "              \"type\": \"string\",\n",
      "            },\n",
      "          },\n",
      "          \"required\": [\n",
      "            \"input\",\n",
      "          ],\n",
      "          \"title\": \"caller\",\n",
      "          \"type\": \"object\",\n",
      "          \"additionalProperties\": false,\n",
      "        },\n",
      "        \"description\": \"person details\",\n",
      "      },\n",
      "    },\n",
      "  ],\n",
      "  \"tool_choice\": {\n",
      "    \"type\": \"auto\",\n",
      "  },\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# the tool_caller will automatically add the tools to the request parameters\n",
    "print(format_json(tool_caller.request_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[{\n",
      "  \"role\": \"system\",\n",
      "  \"content\": \"Use the best tool for the task.\",\n",
      "}, {\n",
      "  \"role\": \"user\",\n",
      "  \"content\": \"Hi, my name is Bob and I'm 42.  I work in a button factory, and my \n",
      "              favorite color is blue.\",\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "introduction = \"\"\"\n",
    "Hi, my name is Bob and I'm 42.  I work in a button factory, and my favorite color is blue.\n",
    "\"\"\".strip()\n",
    "\n",
    "print(tool_caller.render(input=introduction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 20:25:00,034 - DEBUG    - yaaal.core.handler - _invoke:187 - Invoking caller with params: input='Name: Bob, Age: 42, Occupation: Button Factory Worker, Favorite Color: Blue'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Person'>\n",
      "{\n",
      "  \"name\": \"Bob\",\n",
      "  \"age\": 42,\n",
      "  \"favorite_color\": \"Blue\",\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# this should call the person schema tool\n",
    "response = tool_caller(input=introduction)\n",
    "\n",
    "print(type(response))\n",
    "print(format_json(response.model_dump()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 20:25:08,674 - DEBUG    - yaaal.core.handler - _invoke:187 - Invoking MCQAQuestion with params: input='Han Solo is:\\nA. A scoundrel\\nB. A scruffy nerfherder\\nC. A smuggler\\nD. The owner of the Millennium Falcon\\nE. All of the above'\n"
     ]
    }
   ],
   "source": [
    "# this should call the Star Wars QA tool\n",
    "question = \"\"\"\n",
    "Han Solo is:\n",
    "A. A scoundrel\n",
    "B. A scruffy nerfherder\n",
    "C. A smuggler\n",
    "D. The owner of the Millennium Falcon\n",
    "E. All of the above\n",
    "\"\"\".strip()\n",
    "\n",
    "response = tool_caller(input=question)\n",
    "\n",
    "print(type(response))\n",
    "print(format_json(response.model_dump() if hasattr(response, \"model_dump\") else response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "\"Hello! How can I assist you today?\"\n"
     ]
    }
   ],
   "source": [
    "# this should pass through as a normal chat\n",
    "response = tool_caller(input=\"Hello World!\")\n",
    "\n",
    "print(type(response))\n",
    "print(format_json(response.model_dump() if hasattr(response, \"model_dump\") else response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "keep_output": true,
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
