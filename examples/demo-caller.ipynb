{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Caller` is the basic structure that wraps all logic required for LLM call-and-response.\n",
    "\n",
    "A `Caller` associates a `ConversationTemplate` with a specific LLM client and call parameters (assumes OpenAI-compatibility through a framework like `aisuite`).\n",
    "This allows every Caller instance to use a different model and/or parameters, and sets expectations for the Caller instance.\n",
    "Whereas `MessageTemplates` validate _inputs_ to the template and `Handlers` validate the LLM responses, `Callers` make it all happen.\n",
    "\n",
    "Additionally, `Callers` can be used as functions/tools in tool-calling workflows by leveraging `Caller.signature()` which provides the inputs the `Caller.conversation_spec` requires as a JSON schema.\n",
    "Since a `Caller` has a specific client and model assigned, this effectively allows us to use Callers to route to specific models for specific use cases.\n",
    "Since Callers can behave as functions themselves, we enable complex workflows where Callers can call Callers (ad infinitum ad nauseum).\n",
    "\n",
    "Simple factory functions create Callers where the use case is defined by their handlers:\n",
    "\n",
    "- `ChatCaller`: a simple Caller implementation designed for chat messages without response validation.\n",
    "- `RegexCaller`: uses regex for response validation.\n",
    "- `StructuredCaller`: is intended for structured responses, and uses Pydantic for response validation.\n",
    "- `ToolCaller`: a configuration for tool-use; can optionally invoke the tool based on arguments in the LLM's response and return the function results.Simple factory functions create Callers where the use case is defined by their handlers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import textwrap\n",
    "from typing import cast\n",
    "\n",
    "import json_repair\n",
    "from pydantic import BaseModel, Field, ValidationError as PydanticValidationError, create_model\n",
    "\n",
    "import aisuite\n",
    "import openai\n",
    "\n",
    "from yaaal.core.caller import Caller, create_chat_caller, create_structured_caller, create_tool_caller\n",
    "from yaaal.core.handler import ResponseHandler, ToolHandler\n",
    "from yaaal.core.template import (\n",
    "    ConversationTemplate,\n",
    "    JinjaMessageTemplate,\n",
    "    StaticMessageTemplate,\n",
    "    StringMessageTemplate,\n",
    "    UserMessageTemplate,\n",
    ")\n",
    "from yaaal.core.validator import PassthroughValidator, PydanticValidator, RegexValidator, ToolValidator\n",
    "from yaaal.types_.base import JSON\n",
    "from yaaal.types_.core import Conversation, Message\n",
    "from yaaal.utilities import basic_log_config, format_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_log_config()\n",
    "logging.getLogger(\"yaaal\").setLevel(logging.DEBUG)\n",
    "logger = logging.getLogger(__name__).setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all Callers require a client and a model to call.\n",
    "# `yaaal` is built around OpenAI-compatible APIs primarily provided by `aisuite`\n",
    "client = aisuite.Client(\n",
    "    provider_configs={\n",
    "        \"openai\": {\"api_key\": os.environ[\"YAAAL_OPENAI_API_KEY\"]},\n",
    "        \"anthropic\": {\"api_key\": os.environ[\"YAAAL_ANTHROPIC_API_KEY\"]},\n",
    "        # ...\n",
    "    }\n",
    ")\n",
    "# `aisuite` specifies models in \"provider:model\" format\n",
    "# model = \"openai:gpt-4o-mini\"\n",
    "model = \"anthropic:claude-3-5-haiku-latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 20:31:02,088 - DEBUG    - yaaal.core.caller - request_params:110 - All API requests for Caller will use params : {'temperature': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# A `ChatCaller`\n",
    "caller = create_chat_caller(\n",
    "    client=client,\n",
    "    model=model,\n",
    "    request_params={\"temperature\": 0.7},\n",
    "    conversation_template=ConversationTemplate(\n",
    "        name=\"chat\",\n",
    "        description=\"A simple chat\",\n",
    "        conversation_spec=[\n",
    "            Message(\n",
    "                role=\"system\",\n",
    "                content=\"You are a helpful assistant\",\n",
    "            ),\n",
    "            UserMessageTemplate(),\n",
    "        ],\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Caller's call to the LLM is determined by the templates available in the ConversationTemplate and the ConversationSpec specification used to render the output.\n",
    "\n",
    "A `ConversationTemplate` is a way to use various MessageTemplates to render a `Conversation`.\n",
    "ConversationTemplates render the Conversation based on a conversation_spec, a sequence of templates/messages defining the conversation\n",
    "You can provide `ConversationTemplate.render()` dictionary of variables used for rendering the message templates.\n",
    "Each message template in the conversation specification is validated and rendered using these variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"description\": \"A simple chat\",\n",
      "  \"properties\": {\n",
      "    \"user\": {\n",
      "      \"title\": \"User\",\n",
      "      \"type\": \"string\",\n",
      "    },\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"user\",\n",
      "  ],\n",
      "  \"title\": \"chat\",\n",
      "  \"type\": \"object\",\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Caller `schema` attribute is based on its Prompt signature\n",
    "print(format_json(caller.schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"messages\": [\n",
       "    {\n",
       "      \"role\": \"system\",\n",
       "      \"content\": \"You are a helpful assistant\",\n",
       "    },\n",
       "    {\n",
       "      \"role\": \"user\",\n",
       "      \"content\": \"Who is Harry Potter?\",\n",
       "    },\n",
       "  ],\n",
       "}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caller.conversation_template.render(\n",
    "    {\"user\": \"Who is Harry Potter?\"},  # or user=\"Who is Harry Potter?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter is a fictional character and the protagonist of the\n",
      "popular book series written by British author J.K. Rowling. Here are\n",
      "some key details about Harry Potter:\n",
      "\n",
      "1. Background:\n",
      "- An orphaned\n",
      "wizard who survived an attack by the dark wizard Lord Voldemort when\n",
      "he was a baby\n",
      "- Raised by his non-magical (Muggle) aunt and uncle, the\n",
      "Dursleys\n",
      "- Discovers he is a wizard on his 11th birthday and attends\n",
      "Hogwarts School of Witchcraft and Wizardry\n",
      "\n",
      "2. Personal\n",
      "characteristics:\n",
      "- Known for his lightning bolt-shaped scar on his\n",
      "forehead\n",
      "- Brave, loyal, and often stands up against evil\n",
      "- A talented\n",
      "wizard, particularly skilled in Defense Against the Dark Arts\n",
      "- Best\n",
      "friends with Ron Weasley and Hermione Granger\n",
      "\n",
      "3. Story arc:\n",
      "- The\n",
      "main storyline follows Harry's battles against Lord Voldemort\n",
      "- Fights\n",
      "to protect the wizarding world from dark forces\n",
      "- Plays a crucial role\n",
      "in defeating Voldemort in the final book\n",
      "\n",
      "The Harry Potter series\n",
      "consists of seven books that were published between 1997 and 2007, and\n",
      "have since been adapted into a successful film franchise.\n"
     ]
    }
   ],
   "source": [
    "# callers are called as functions to get the response from the LLM\n",
    "response = caller(**{\"user\": \"Who is Harry Potter?\"})\n",
    "\n",
    "print(textwrap.fill(response, replace_whitespace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 20:31:14,404 - WARNING  - yaaal.core.template - name:339 - Converted template name 'Star Wars QA' to 'star_wars_qa'\n",
      "2025-03-06 20:31:14,405 - DEBUG    - yaaal.core.caller - request_params:110 - All API requests for Caller will use params : {'temperature': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# A `RegexCaller` validates the response with a regex pattern\n",
    "pattern = re.compile(r\"\\b[A-E]\\b(?!.*\\b[A-E]\\b)\")\n",
    "\n",
    "system_instructions = \"\"\"\n",
    "The following are multiple choice questions (with answers) about Star Wars.\n",
    "\n",
    "What is the model designation of an X-Wing?\n",
    "A. T-65B\n",
    "B. BTL-A4\n",
    "C. RZ-1\n",
    "D. A/SF-01\n",
    "Answer: A\n",
    "\"\"\"\n",
    "\n",
    "user_template = \"\"\"\n",
    "{{question}}\n",
    "Answer:\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "class MCQAQuestion(BaseModel):\n",
    "    question: str = Field(description=\"The multiple choice question\")\n",
    "\n",
    "\n",
    "regex_caller = Caller(\n",
    "    client=client,\n",
    "    model=model,\n",
    "    request_params={\"temperature\": 0.7},\n",
    "    conversation_template=ConversationTemplate(\n",
    "        name=\"Star Wars QA\",\n",
    "        description=\"Multiple-choice question answering\",\n",
    "        conversation_spec=[\n",
    "            StaticMessageTemplate(role=\"system\", template=system_instructions),\n",
    "            JinjaMessageTemplate(role=\"user\", template=user_template, validation_model=MCQAQuestion),\n",
    "        ],\n",
    "    ),\n",
    "    handler=ResponseHandler(validator=RegexValidator(pattern=pattern)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E\n",
      "Success! ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "Han Solo is:\n",
    "A. A scoundrel\n",
    "B. A scruffy nerfherder\n",
    "C. A smuggler\n",
    "D. The owner of the Millennium Falcon\n",
    "E. All of the above\n",
    "\"\"\".strip()\n",
    "\n",
    "response = regex_caller(**{\"question\": question})\n",
    "print(response)\n",
    "\n",
    "if response == \"E\":\n",
    "    print(\"Success! ðŸŽ‰\")\n",
    "# print(textwrap.fill(response, replace_whitespace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 20:31:16,248 - WARNING  - yaaal.core.template - name:339 - Converted template name 'person details' to 'person_details'\n",
      "2025-03-06 20:31:16,250 - DEBUG    - yaaal.core.caller - request_params:110 - All API requests for Caller will use params : {'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'Person', 'strict': True, 'parameters': {'description': \"A Person's characteristics.\", 'properties': {'name': {'title': 'Name', 'type': 'string'}, 'age': {'title': 'Age', 'type': 'integer'}, 'favorite_color': {'title': 'Favorite Color', 'type': 'string'}}, 'required': ['name', 'age', 'favorite_color'], 'title': 'Person', 'type': 'object', 'additionalProperties': False}, 'description': \"A Person's characteristics.\"}}], 'tool_choice': {'type': 'tool', 'name': 'Person'}}\n"
     ]
    }
   ],
   "source": [
    "# A `StructuredCaller` validates the response with a Pydantic model, and is good for structure data extraction\n",
    "class Person(BaseModel, extra=\"ignore\"):\n",
    "    \"\"\"A Person's characteristics.\"\"\"\n",
    "\n",
    "    name: str\n",
    "    age: int\n",
    "    favorite_color: str\n",
    "\n",
    "\n",
    "# Notes on fstrings with jinja templates --\n",
    "# The fstring allows us to substitute in variables before\n",
    "# dynamically rendering the template in the Prompt.\n",
    "# Because we're using fstrings, we have to double the `{}`\n",
    "# so python understands they do not indicate an fstring substitution.\n",
    "system_instructions = f\"\"\"\n",
    "Identify facts about a person as they introduce themselves.\n",
    "\n",
    "Respond in a format that matches the following json schema:\n",
    "\n",
    "<schema>\n",
    "{Person.model_json_schema()}\n",
    "</schema>\n",
    "\"\"\".strip()\n",
    "\n",
    "structured_caller = create_structured_caller(\n",
    "    client=client,\n",
    "    model=model,\n",
    "    request_params={\"temperature\": 0.7},\n",
    "    conversation_template=ConversationTemplate(\n",
    "        name=\"person details\",\n",
    "        description=\"Identify details about a person\",\n",
    "        conversation_spec=[\n",
    "            StaticMessageTemplate(role=\"system\", template=system_instructions),\n",
    "            UserMessageTemplate(),\n",
    "        ],\n",
    "    ),\n",
    "    response_model=Person,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Person'>\n",
      "{\n",
      "  \"name\": \"Bob\",\n",
      "  \"age\": 42,\n",
      "  \"favorite_color\": \"blue\",\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "introduction = \"\"\"\n",
    "Hi, my name is Bob and I'm 42.  I work in a button factory, and my favorite color is blue.\n",
    "\"\"\".strip()\n",
    "\n",
    "response = structured_caller(\n",
    "    user=introduction,  # or **{\"user\": introduction}\n",
    ")\n",
    "\n",
    "print(type(response))\n",
    "print(format_json(response.model_dump()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callers using Pydantic Handlers still return an AssistantMessage; it was validated internally before returning to the user.\n",
    "\n",
    "This means we still have to re-validate if we want the response as a Pydantic model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 20:31:21,879 - WARNING  - yaaal.core.template - name:339 - Converted template name 'tool use' to 'tool_use'\n",
      "2025-03-06 20:31:21,881 - DEBUG    - yaaal.core.caller - request_params:110 - All API requests for Caller will use params : {'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'star_wars_qa', 'strict': True, 'parameters': {'description': 'Multiple-choice question answering', 'properties': {'question': {'description': 'The multiple choice question', 'title': 'Question', 'type': 'string'}}, 'required': ['question'], 'title': 'star_wars_qa', 'type': 'object', 'additionalProperties': False}, 'description': 'Multiple-choice question answering'}}, {'type': 'function', 'function': {'name': 'person_details', 'strict': True, 'parameters': {'description': 'Identify details about a person', 'properties': {'user': {'title': 'User', 'type': 'string'}}, 'required': ['user'], 'title': 'person_details', 'type': 'object', 'additionalProperties': False}, 'description': 'Identify details about a person'}}], 'tool_choice': {'type': 'auto'}}\n"
     ]
    }
   ],
   "source": [
    "# A `ToolCaller` can choose to call tools or respond like a normal LLM.\n",
    "tool_caller = create_tool_caller(\n",
    "    client=client,\n",
    "    model=model,\n",
    "    request_params={\"temperature\": 0.7},\n",
    "    conversation_template=ConversationTemplate(\n",
    "        name=\"tool use\",\n",
    "        description=\"Determine which tool to use\",\n",
    "        conversation_spec=[\n",
    "            Message(role=\"system\", content=\"Use the best tool for the task.\"),\n",
    "            UserMessageTemplate(),\n",
    "        ],\n",
    "    ),\n",
    "    toolbox=[regex_caller, structured_caller],  # use other callers as tools!\n",
    "    auto_invoke=True,  # make the recommended tool call\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"temperature\": 0.7,\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"star_wars_qa\",\n",
      "        \"strict\": true,\n",
      "        \"parameters\": {\n",
      "          \"description\": \"Multiple-choice question answering\",\n",
      "          \"properties\": {\n",
      "            \"question\": {\n",
      "              \"description\": \"The multiple choice question\",\n",
      "              \"title\": \"Question\",\n",
      "              \"type\": \"string\",\n",
      "            },\n",
      "          },\n",
      "          \"required\": [\n",
      "            \"question\",\n",
      "          ],\n",
      "          \"title\": \"star_wars_qa\",\n",
      "          \"type\": \"object\",\n",
      "          \"additionalProperties\": false,\n",
      "        },\n",
      "        \"description\": \"Multiple-choice question answering\",\n",
      "      },\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"person_details\",\n",
      "        \"strict\": true,\n",
      "        \"parameters\": {\n",
      "          \"description\": \"Identify details about a person\",\n",
      "          \"properties\": {\n",
      "            \"user\": {\n",
      "              \"title\": \"User\",\n",
      "              \"type\": \"string\",\n",
      "            },\n",
      "          },\n",
      "          \"required\": [\n",
      "            \"user\",\n",
      "          ],\n",
      "          \"title\": \"person_details\",\n",
      "          \"type\": \"object\",\n",
      "          \"additionalProperties\": false,\n",
      "        },\n",
      "        \"description\": \"Identify details about a person\",\n",
      "      },\n",
      "    },\n",
      "  ],\n",
      "  \"tool_choice\": {\n",
      "    \"type\": \"auto\",\n",
      "  },\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# the tool_caller will automatically add the tools to the request parameters\n",
    "print(format_json(tool_caller.request_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 20:31:24,624 - DEBUG    - yaaal.core.handler - _invoke:183 - Invoking person_details with params: user='Bob'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Person'>\n",
      "{\n",
      "  \"name\": \"Bob\",\n",
      "  \"age\": 35,\n",
      "  \"favorite_color\": \"blue\",\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# this should call the person schema tool\n",
    "introduction = \"\"\"\n",
    "Hi, my name is Bob and I'm 42.  I work in a button factory, and my favorite color is blue.\n",
    "\"\"\".strip()\n",
    "\n",
    "response = tool_caller(**{\"user\": introduction})\n",
    "\n",
    "print(type(response))\n",
    "print(format_json(response.model_dump()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 20:31:30,248 - DEBUG    - yaaal.core.handler - _invoke:183 - Invoking star_wars_qa with params: question='Han Solo is:\\nA. A scoundrel\\nB. A scruffy nerfherder\\nC. A smuggler\\nD. The owner of the Millennium Falcon\\nE. All of the above'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "\"E\"\n"
     ]
    }
   ],
   "source": [
    "# this should call the Star Wars QA tool\n",
    "question = \"\"\"\n",
    "Han Solo is:\n",
    "A. A scoundrel\n",
    "B. A scruffy nerfherder\n",
    "C. A smuggler\n",
    "D. The owner of the Millennium Falcon\n",
    "E. All of the above\n",
    "\"\"\".strip()\n",
    "\n",
    "response = tool_caller(**{\"user\": question})\n",
    "\n",
    "print(type(response))\n",
    "print(format_json(response.model_dump() if isinstance(response, BaseModel) else response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "\"Hello there! It seems like you've just said a classic programming greeting. Is there anything specific I can help you with today? I have access to some Star Wars-related Q&A and person details tools if you're interested in exploring those.\"\n"
     ]
    }
   ],
   "source": [
    "# this should pass through as a normal chat\n",
    "response = tool_caller(**{\"user\": \"Hello World!\"})\n",
    "\n",
    "print(type(response))\n",
    "print(format_json(response.model_dump() if isinstance(response, BaseModel) else response))"
   ]
  }
 ],
 "metadata": {
  "keep_output": true,
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
